{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFineData(row): return row['enrollGroups'][0]['classSections'][0]['meetings']\n",
    "def getProf(row): \n",
    "  x = lambda r: r[0]['instructors'][0]['firstName'].strip() + ' '+r[0]['instructors'][0]['lastName'].strip()\n",
    "  try: \n",
    "    return x(row)\n",
    "  except: return \"\"\n",
    "def getData(fineData, obj): \n",
    "  try:\n",
    "    x = lambda r: r[0][obj]\n",
    "    return x(fineData)\n",
    "  except: return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_class_roster(sem, csv_name):\n",
    "  subjects_url = 'https://classes.cornell.edu/api/2.0/config/subjects.json?roster='+sem\n",
    "  subjects_json = json.loads(urllib.request.urlopen(subjects_url).read())\n",
    "  subject_list = [x['value'] for x in subjects_json['data']['subjects']]\n",
    "  courses = pd.DataFrame(columns = [\"Dept\", \"Number\", \"Course_Name\", \"Professor\",\"Start_Time\", \"End_Time\", \"Location\",\"Description\",\"Pre/coreqs\",\"Offered\"])\n",
    "\n",
    "  for subject in subject_list: \n",
    "    url = \"https://classes.cornell.edu/api/2.0/search/classes.json?roster=\"+sem+f\"&subject={subject}\"\n",
    "    data_json = json.loads(urllib.request.urlopen(url).read())\n",
    "    df = pd.DataFrame(data_json['data']['classes'])\n",
    "\n",
    "    df['prof'] = df.apply(lambda row: getProf( getFineData(row)), axis=1)\n",
    "    df['startTime'] = df.apply(lambda row: getData(getFineData(row), 'timeStart'), axis=1)  \n",
    "    df['endTime'] = df.apply(lambda row: getData(getFineData(row), 'timeEnd'), axis=1)  \n",
    "    df['location'] = df.apply(lambda row: getData(getFineData(row), 'facilityDescr'), axis=1)  \n",
    "\n",
    "    df = df[[\"subject\", \"catalogNbr\", \"titleShort\", \"prof\", \"startTime\", \"endTime\", \"location\", \"description\", \"catalogPrereqCoreq\", \"catalogWhenOffered\"]]\n",
    "    df = df.rename(columns={\"subject\": \"Dept\", 'catalogNbr':\"Number\", \"titleShort\":\"Course_Name\", \"prof\":\"Professor\", \"startTime\":\"Start_Time\", \"endTime\":\"End_Time\", \"location\": \"Location\", \"description\":\"Description\", \"catalogPrereqCoreq\":\"Pre/coreqs\", \"catalogWhenOffered\":\"Offered\"})\n",
    "\n",
    "    courses = courses.merge(df, how='outer') \n",
    "\n",
    "  courses.to_csv('data/class_roster_'+sem+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = \"SP22\"\n",
    "scrape_class_roster(sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = \"FA22\"\n",
    "scrape_class_roster(sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_cureviews (courses):\n",
    "  url = 'https://www.cureviews.org/v2/getCourseByInfo/'\n",
    "  courses['Dept + Number'] = courses.Dept + \" \" + courses.Number.map(str)\n",
    "\n",
    "  class_diff = {}\n",
    "  rating = {}\n",
    "  workload = {}\n",
    "\n",
    "  for index, row in courses['Dept + Number'].iteritems():\n",
    "    try:\n",
    "      jsn = {'number':int(row.split(' ')[1]), 'subject':row.split(' ')[0].lower()}\n",
    "      # print(jsn)\n",
    "      result = requests.post(url, json=jsn).json()['result']\n",
    "      class_diff[row] = result['classDifficulty']\n",
    "      rating[row] = result['classRating']\n",
    "      workload[row] = result['classWorkload']\n",
    "      \n",
    "    except:\n",
    "      class_diff[row] = \"\"\n",
    "      rating[row] = \"\"\n",
    "      workload[row] = \"\"\n",
    "  \n",
    "  courses[\"class_diff\"] = courses['Dept + Number'].map(class_diff)\n",
    "  courses[\"rating\"] = courses['Dept + Number'].map(rating)\n",
    "  courses[\"workload\"] = courses['Dept + Number'].map(workload)\n",
    "\n",
    "  return courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_FA = scrape_cureviews(pd.read_csv('data/class_roster_FA22.csv'))\n",
    "courses_SP = scrape_cureviews(pd.read_csv('data/class_roster_SP22.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_FA.to_csv('data/CUReviews_FA22')\n",
    "courses_SP.to_csv('data/CUReviews_SP22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# courses_FA = pd.read_csv('data/CUReviews_FA22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = courses_FA.merge(courses_SP, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rate My Prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/tisuela/ratemyprof-api/tree/master/ratemyprof_api\n",
    "from professor import *\n",
    "from ratemyprof_api import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmp = RateMyProfApi(298).scrape_professors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aditya Manthri\n"
     ]
    }
   ],
   "source": [
    "num_ratings = {}\n",
    "prof_rat = {}\n",
    "prof_diff = {}\n",
    "# count = 0\n",
    "for prof in rmp:\n",
    "    \n",
    "    try:\n",
    "        result = urllib.requests.get(\"https://www.ratemyprofessors.com/ShowRatings.jsp?tid=\" + str(prof))\n",
    "        page = result.content.decode('utf-8')\n",
    "\n",
    "        num_ratings[rmp[prof].name] = rmp[prof].num_of_ratings\n",
    "        prof_rat[rmp[prof].name] = rmp[prof].overall_rating\n",
    "        diff = page.index('avgDifficulty')\n",
    "        prof_diff[rmp[prof].name] = page[page.index(':', diff + 1)+1:page.index(',', diff + 1)]\n",
    "        \n",
    "    except:\n",
    "        print(rmp[prof].name)\n",
    "    # count += 1\n",
    "    # if count > 10:\n",
    "        # assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profs = []\n",
    "for prof in rmp:\n",
    "    profs.append(rmp[prof].name)\n",
    "prof_info = pd.DataFrame(columns = ['Professor', 'num_ratings', 'prof_rat', 'prof_diff'])\n",
    "prof_info['Professor'] = profs\n",
    "\n",
    "prof_info['num_ratings'] = prof_info['Professor'].map(num_ratings)\n",
    "prof_info['prof_rat'] = prof_info['Professor'].map(prof_rat)\n",
    "prof_info['prof_diff'] = prof_info['Professor'].map(prof_diff)\n",
    "prof_info.to_csv('data/rmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof_info = pd.read_csv('data/rmp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_w_prof = courses.merge(prof_info, on=\"Professor\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = pd.read_csv('data/CornellMedianGrades.csv')\n",
    "medians = medians[1:]\n",
    "\n",
    "course_medians = courses_w_prof.merge(medians, on=\"Dept + Number\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_medians = course_medians.drop_duplicates(subset=['Dept + Number', 'Professor_x', 'Semester (Ex: SP21)'])\n",
    "course_medians.to_csv('data/merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2d44e5b173de06ea48055461fbb3130df4a0cdec4b6d57544ee834ff1f5ce7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
